GNN (redes neuronales de grafico)
Grafo: puntos conectados, escrito en latin, punto a inicio, camino y destino, podemos procesar datos de forma diferente a 
las tablas, con las redes neuronales de grafo podemos hacer cosas diferentes, generan un contexto GCN, buscamos usar 
PytorchGeometric version 2
grafo en 4 dimensiones, 3 dimensiones y varianle tiempo
Nos dan un contexto completamente diferente para los datos, gestiona la automatizacion para buscar caminos, no ha base de 
entrenar
si no a base de usar otros caminos minimos, usamos tambien networkx como libreria principal 
Entidad relacion, tablas. Imaginalo como Packet tracer, se usa para relaciones entre objetos, 

Clasificacion de nodos segun patrones, saca tensores, hacemos lo mismo de siempre(sacamos un patron con ese tensor haciendo
una matriz)
Edge computing: Es un modelo informático distribuido que acerca el procesamiento y almacenamiento de datos 
a la fuente de generación, como dispositivos IoT, cámaras de vigilancia o sensores, en lugar de enviarlos a centros de datos
o la nube centralizada.  Este enfoque reduce significativamente la latencia, mejora los tiempos de respuesta y ahorra ancho 
de banda, lo que es esencial para aplicaciones que requieren decisiones en tiempo real
nos permite respuestas inmediatas, es justo lo contrario de las RNN, en vez de tener el cloud computing, lo tenemos en
local, para menor latencia y que sea instantaneo.
Debemos guardar los datos en una base de datos super rapida para eso usamos:
spaning tree: usa el numero minimo de aristas, conectando nodos con aristas y las aristas nos dan el camino mas rapido
no nos da la informacion, pero si la cabezera de esos datos
Vamos a entender como pintamos las cabeceras en las tcp
dentro de las gnn trabajamos con nodos y aristas
los nodos son las rotondas en terminos de carretera las aristas son los puntos que van de rotonda a rotonda, las mejores 
aristas son las que tienen mas curvas, una carretera son dos puntos entre rotondas.
Teoria de grafos lo del tiempo relativo y los nodos y aristas, buscar una ruta alternativa la mas rapida
Redes, variable espacio para que el canal se amplie (datos) mesh computing.
Conexiones de grafo son: Dos listas son dos objetos dos dimensiones(en el ejemplo)
uno almacena nodos origen y otra los nodos destino
(Metodo del chisme goship) asi se expande el chisme por todos lados muy rapido, como en un pueblo pequeño
chisme computacional, push y pull como github
canal fino mesh
canal gordo chisme
deben de haber varios agentes para determinar si va al cloud computing o al mesh
Partimos de que no estan cifrados
tablas de hash, varias tablas resultan en hashear, hacer un bloques de cifrado, blockchain
Para ipsf, debemos buscar por contenido, que es el archivo, red persona a persona, los datos estan cortados y distribuidos y
alguien tiene una llave para juntar todos esos datos, al dividir el archivo le mete hash y solo al quitarle el hash tienes el
archivo completo
las matrices dispersas (las bases de datos) tienen un primary key imaginalo como una yincana si tengo 2000 datos lo reparto
en 4 sitios de 500 la idea es que si pillan una parte no tengan el total.
Listas de coordenadas, matriz de adyacencia, donde hay 1 se tocan donde hay 0 no se toca
Una matriz de adyacencia no es eficiente con las coordenadas, se infiere apartir del edge, solo quiero los 1s
Ponemos etiquetas, que nos define el almacenar los datos de forma eficiente, pasando por encima de estos. Solo se leen estas
etiquetas a modo de indice clasificandolas, usamos las etiquetas obviando que los datos de dentro estan ya procesados
La mascara da el tamaño del tubo
Le pasamos una mascara a la matriz  1 true 0 false , despues nos cargamos los nodos que no tengan contenido, se separan 
en forma de test y train la mascara nos muestra cuales usar para el entrenamiento y cuales para el test 
si el grafo es dirigido significa que no es simetrica, la direccion de las aristas influye en las conexiones entre nodos.
Neo 4J, cosmo DB

Red convolucional, cnn (matriz y filtros) se aplica un filtro para que a + b sea c transformacion lineal de los datos 
que entran mas los datos que salen.
Les añadimos las conexiones entre los nodos.
Las capas ocultas, sigmoides, filtros de las redes neuronales, adam, donde ponemos los pesos que nodo tiene mas probabilidad
si un nodo solo tiene un vecino y otro tiene 500 imagina que todas las personas quieren salir a la vez eso es lo que significa 
la matriz y los vecinos, por lo que hay que normalizar los resultados, adaptandose al numero x de vecinos.
Si metemos la convolucional se pueden hacer mayores ponderaciones.

implementacion de GCN, nos da una serie de capas, funciona solo mediante una ReLu (funcion de activacion) y una capa de salida 
lineal. 
Con gran trafico de informacion puede llegar a colapsar la red si no hay infraestructura suficientemente capaz de canalizar
Todos los grafos pueden ser entendidos como un alcantarillado donde el flujo de datos no es constante, para eso usamos las
ReLu para activar o desactivar donde todo este a 0 para pasarlas a activado cuando pase un dato de una señal.
(Estanque de tormentas)
Les metemos varias capas de mallado (apilar varias capas de graficos)
El ciclo de entrenamiento es estandar 
Normalizamos la tabla para poder verlo en 3d los grafos nos va a interesar que estemos en 3d para cualquier grafo

Redes de atencion Grafica, Autoatencion.

En lugar de calcular pesos estaticos basados en grados de los nodos se asignan pesos dinamicos mediante un metodo llamado 
autoatencion, La idea principal de las GAT es que algunos vecinos son mas importantes que otros independientemente de sus
grados de nodo, la variable fundamental es el tiempo, pues a lo largo del tiempo cambia esos datos estaticos, lo que buscamos 
es que el entrenamiento sea casi al instante.
Un jefe ordena y quiere una cosa fija haces un reporte y ya
Un lider comparte su vision y enseña, no te manda, deja que aprendas, da autonomia
Algoritmo de consenso
























