GNN (redes neuronales de grafico)
Grafo: puntos conectados, escrito en latin, punto a inicio, camino y destino, podemos procesar datos de forma diferente a 
las tablas, con las redes neuronales de grafo podemos hacer cosas diferentes, generan un contexto GCN, buscamos usar 
PytorchGeometric version 2
grafo en 4 dimensiones, 3 dimensiones y varianle tiempo
Nos dan un contexto completamente diferente para los datos, gestiona la automatizacion para buscar caminos, no ha base de 
entrenar
si no a base de usar otros caminos minimos, usamos tambien networkx como libreria principal 
Entidad relacion, tablas. Imaginalo como Packet tracer, se usa para relaciones entre objetos, 

Clasificacion de nodos segun patrones, saca tensores, hacemos lo mismo de siempre(sacamos un patron con ese tensor haciendo
una matriz)
Edge computing: Es un modelo informático distribuido que acerca el procesamiento y almacenamiento de datos 
a la fuente de generación, como dispositivos IoT, cámaras de vigilancia o sensores, en lugar de enviarlos a centros de datos
o la nube centralizada.  Este enfoque reduce significativamente la latencia, mejora los tiempos de respuesta y ahorra ancho 
de banda, lo que es esencial para aplicaciones que requieren decisiones en tiempo real
nos permite respuestas inmediatas, es justo lo contrario de las RNN, en vez de tener el cloud computing, lo tenemos en
local, para menor latencia y que sea instantaneo.
Debemos guardar los datos en una base de datos super rapida para eso usamos:
spaning tree: usa el numero minimo de aristas, conectando nodos con aristas y las aristas nos dan el camino mas rapido
no nos da la informacion, pero si la cabezera de esos datos
Vamos a entender como pintamos las cabeceras en las tcp
dentro de las gnn trabajamos con nodos y aristas
los nodos son las rotondas en terminos de carretera las aristas son los puntos que van de rotonda a rotonda, las mejores 
aristas son las que tienen mas curvas, una carretera son dos puntos entre rotondas.
Teoria de grafos lo del tiempo relativo y los nodos y aristas, buscar una ruta alternativa la mas rapida
Redes, variable espacio para que el canal se amplie (datos) mesh computing.
Conexiones de grafo son: Dos listas son dos objetos dos dimensiones(en el ejemplo)
uno almacena nodos origen y otra los nodos destino
(Metodo del chisme goship) asi se expande el chisme por todos lados muy rapido, como en un pueblo pequeño
chisme computacional, push y pull como github
canal fino mesh
canal gordo chisme
deben de haber varios agentes para determinar si va al cloud computing o al mesh
Partimos de que no estan cifrados
tablas de hash, varias tablas resultan en hashear, hacer un bloques de cifrado, blockchain
Para ipsf, debemos buscar por contenido, que es el archivo, red persona a persona, los datos estan cortados y distribuidos y
alguien tiene una llave para juntar todos esos datos, al dividir el archivo le mete hash y solo al quitarle el hash tienes el
archivo completo
las matrices dispersas (las bases de datos) tienen un primary key imaginalo como una yincana si tengo 2000 datos lo reparto
en 4 sitios de 500 la idea es que si pillan una parte no tengan el total.
Listas de coordenadas, matriz de adyacencia, donde hay 1 se tocan donde hay 0 no se toca
Una matriz de adyacencia no es eficiente con las coordenadas, se infiere apartir del edge, solo quiero los 1s
Ponemos etiquetas, que nos define el almacenar los datos de forma eficiente, pasando por encima de estos. Solo se leen estas
etiquetas a modo de indice clasificandolas, usamos las etiquetas obviando que los datos de dentro estan ya procesados
La mascara da el tamaño del tubo
Le pasamos una mascara a la matriz  1 true 0 false , despues nos cargamos los nodos que no tengan contenido, se separan 
en forma de test y train la mascara nos muestra cuales usar para el entrenamiento y cuales para el test 
si el grafo es dirigido significa que no es simetrica, la direccion de las aristas influye en las conexiones entre nodos.
Neo 4J, cosmo DB

Red convolucional, cnn (matriz y filtros) se aplica un filtro para que a + b sea c transformacion lineal de los datos 
que entran mas los datos que salen.
Les añadimos las conexiones entre los nodos.
Las capas ocultas, sigmoides, filtros de las redes neuronales, adam, donde ponemos los pesos














